{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73290,"databundleVersionId":8710574,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/anshulm257/eda-selecting-best-features-comparing-3-models?scriptVersionId=183142472\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-12T22:37:07.766926Z","iopub.execute_input":"2024-06-12T22:37:07.767307Z","iopub.status.idle":"2024-06-12T22:37:11.466477Z","shell.execute_reply.started":"2024-06-12T22:37:07.767275Z","shell.execute_reply":"2024-06-12T22:37:11.46539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s4e6/train.csv', index_col='id')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e6/test.csv', index_col='id')\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:11.469045Z","iopub.execute_input":"2024-06-12T22:37:11.469565Z","iopub.status.idle":"2024-06-12T22:37:12.225705Z","shell.execute_reply.started":"2024-06-12T22:37:11.469534Z","shell.execute_reply":"2024-06-12T22:37:12.224462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:12.227693Z","iopub.execute_input":"2024-06-12T22:37:12.22802Z","iopub.status.idle":"2024-06-12T22:37:12.262702Z","shell.execute_reply.started":"2024-06-12T22:37:12.227992Z","shell.execute_reply":"2024-06-12T22:37:12.261556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train.columns:\n    print(f'{col} has {train[col].nunique()} values')","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:12.266169Z","iopub.execute_input":"2024-06-12T22:37:12.266534Z","iopub.status.idle":"2024-06-12T22:37:12.30685Z","shell.execute_reply.started":"2024-06-12T22:37:12.266503Z","shell.execute_reply":"2024-06-12T22:37:12.305593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(10, 8))\nax = sns.countplot(x='Target', data=train, palette='pastel')\n\n# Add labels to each bar in the plot\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width() / 2, p.get_height() + 3, f'{int(p.get_height())}', ha=\"center\")\n\nplt.xlabel('Target')\nplt.ylabel('Count')\nplt.title('Target Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:12.308464Z","iopub.execute_input":"2024-06-12T22:37:12.308846Z","iopub.status.idle":"2024-06-12T22:37:12.738913Z","shell.execute_reply.started":"2024-06-12T22:37:12.308815Z","shell.execute_reply":"2024-06-12T22:37:12.737682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_counts = train.nunique()\n\nthreshold = 12\ncontinuous_vars = unique_counts[unique_counts > threshold].index.tolist()\ncategorical_vars = unique_counts[unique_counts <= threshold].index.tolist()\nif 'id' in continuous_vars:\n    continuous_vars.remove('id')","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:12.74051Z","iopub.execute_input":"2024-06-12T22:37:12.741Z","iopub.status.idle":"2024-06-12T22:37:12.7812Z","shell.execute_reply.started":"2024-06-12T22:37:12.740954Z","shell.execute_reply":"2024-06-12T22:37:12.77982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_palette = sns.color_palette(\"deep\")\n\nfor column in categorical_vars:\n    f, ax = plt.subplots(1, 2, figsize=(18, 5.5))\n    train[column].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[0], shadow=True, colors=custom_palette)\n    ax[0].set_ylabel(f'{column}')\n    sns.countplot(x=column, data=train, ax=ax[1], palette=custom_palette)\n    ax[0].set_title(f'{column} Distribution (Pie Chart)', fontsize=14)\n    ax[1].set_title(f'{column} Count (Bar Plot)', fontsize=14)\n    plt.suptitle(f'{column} Visualization', fontsize=16, fontweight='bold')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:12.783267Z","iopub.execute_input":"2024-06-12T22:37:12.783754Z","iopub.status.idle":"2024-06-12T22:37:20.048023Z","shell.execute_reply.started":"2024-06-12T22:37:12.783714Z","shell.execute_reply":"2024-06-12T22:37:20.046685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classify columns for better visualization\n# Categorical columns: if the number of unique values is 8 or fewer\ncat_cols = [col for col in train.columns if train[col].nunique() <= 8]\n# Numerical columns: if the number of unique values is 9 or more\nnum_cols = [col for col in train.columns if train[col].nunique() >= 9]","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:20.049525Z","iopub.execute_input":"2024-06-12T22:37:20.050018Z","iopub.status.idle":"2024-06-12T22:37:20.117504Z","shell.execute_reply.started":"2024-06-12T22:37:20.049972Z","shell.execute_reply":"2024-06-12T22:37:20.116096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18, 135))\nplotnumber = 1\n\nfor col in num_cols:\n    if plotnumber <= len(num_cols):\n        \n        ax1 = plt.subplot(len(num_cols), 2, 2 * plotnumber - 1)\n        sns.kdeplot(train[col], color='salmon', fill=True)\n        for spine in ax1.spines.values():\n            spine.set_visible(True)\n            spine.set_color('black')\n            spine.set_linewidth(0.5)\n        ax1.set_xlabel(col)\n        ax1.grid(False)\n        \n        ax2 = plt.subplot(len(num_cols), 2, 2 * plotnumber)\n        sns.boxplot(y=train[col], color='salmon', width=0.6, linewidth=1)\n        for spine in ax2.spines.values():\n            spine.set_visible(True)\n            spine.set_color('black')\n            spine.set_linewidth(0.5)\n        ax2.set_xlabel(col)\n        ax2.set_ylabel('')\n        ax2.grid(False)\n\n    plotnumber += 1\n\nplt.suptitle('Distribution of Numeric Variables', fontsize=40, y=1)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:20.119414Z","iopub.execute_input":"2024-06-12T22:37:20.119847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.sample(5)","metadata":{"execution":{"iopub.execute_input":"2024-06-12T22:37:42.351679Z","iopub.status.idle":"2024-06-12T22:37:42.391462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ncategories = ['dropout', 'enrolled', 'graduate']\nlabel_encoder = LabelEncoder()\n\n# Convert categorical 'Target' labels to numeric values using LabelEncoder\ntrain['Target'] = label_encoder.fit_transform(train['Target'])","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:42.393189Z","iopub.execute_input":"2024-06-12T22:37:42.393706Z","iopub.status.idle":"2024-06-12T22:37:42.724279Z","shell.execute_reply.started":"2024-06-12T22:37:42.393653Z","shell.execute_reply":"2024-06-12T22:37:42.723147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix\nplt.figure(figsize=(21, 18))\nsns.heatmap(train.corr(), annot=True, cmap='coolwarm', fmt='.1f', linewidths=2, linecolor='lightgrey')\nplt.suptitle('Correlation Matrix', fontsize=40, y=1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:42.725911Z","iopub.execute_input":"2024-06-12T22:37:42.726357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train.drop(columns=[\"Target\"])\ny_train = train[\"Target\"]\n#X_train, X_val, y_train,y_val= train_test_split(X, y, test_size=0.2, random_state=42)\nX_test = test.copy()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:47.070842Z","iopub.execute_input":"2024-06-12T22:37:47.071207Z","iopub.status.idle":"2024-06-12T22:37:47.086494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\n\ndef cross_validate_model(model, X_train, y_train, params, n_splits=10):\n    \"\"\"\n    Performs K-Fold cross-validation for a given model, returns the last model and average validation accuracy.\n\n    Parameters:\n        model: Machine learning model class (e.g., RandomForestClassifier)\n        X_train: Training feature dataset\n        y_train: Training target dataset\n        params: Dictionary of parameters to initialize the model\n        n_splits: Number of folds for cross-validation (default: 10)\n\n    Returns:\n        last_model: The last trained model instance\n        average_val_accuracy: Average validation accuracy over all folds\n    \"\"\"\n    # Initialize variables\n    cv = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n    val_scores = []\n\n    # Cross-validation loop\n    for fold, (train_ind, valid_ind) in enumerate(cv.split(X_train)):\n        # Data splitting\n        X_fold_train = X_train.iloc[train_ind]\n        y_fold_train = y_train.iloc[train_ind]\n        X_val = X_train.iloc[valid_ind]\n        y_val = y_train.iloc[valid_ind]\n        \n        # Model initialization and training\n        clf = model(**params)\n        clf.fit(X_fold_train, y_fold_train)\n        \n        # Predict and evaluate\n        y_pred_trn = clf.predict(X_fold_train)\n        y_pred_val = clf.predict(X_val)\n        train_acc = accuracy_score(y_fold_train, y_pred_trn)\n        val_acc = accuracy_score(y_val, y_pred_val)\n        print(f\"Fold: {fold}, Train Accuracy: {train_acc:.5f}, Val Accuracy: {val_acc:.5f}\")\n        print(\"-\" * 50)\n        \n        # Accumulate validation scores\n        val_scores.append(val_acc)\n\n    # Calculate the average validation score\n    average_val_accuracy = np.mean(val_scores)\n    print(\"Average Validation Accuracy:\", average_val_accuracy)\n\n    return clf, average_val_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:47.08886Z","iopub.execute_input":"2024-06-12T22:37:47.089332Z","iopub.status.idle":"2024-06-12T22:37:47.221024Z","shell.execute_reply.started":"2024-06-12T22:37:47.08929Z","shell.execute_reply":"2024-06-12T22:37:47.219664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nprint('XGBoost Cross-Validation Results:\\n')\nxgb_model, xgb_mean_accuracy = cross_validate_model(XGBClassifier, X_train, y_train, params={})","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:37:47.223045Z","iopub.execute_input":"2024-06-12T22:37:47.223523Z","iopub.status.idle":"2024-06-12T22:38:37.322345Z","shell.execute_reply.started":"2024-06-12T22:37:47.223479Z","shell.execute_reply":"2024-06-12T22:38:37.321332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the test set and reverse the label encoding\nxgb_preds = xgb_model.predict(X_test)\nxgb_preds_labels = label_encoder.inverse_transform(xgb_preds)\n\n# Save the predictions to a CSV file\nxgb_result = pd.DataFrame(X_test.index)\nxgb_result['Target'] = xgb_preds_labels\n#xgb_result.to_csv('result_xgb.csv', index=False)\nxgb_result","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:38:37.326799Z","iopub.execute_input":"2024-06-12T22:38:37.328105Z","iopub.status.idle":"2024-06-12T22:38:37.518318Z","shell.execute_reply.started":"2024-06-12T22:38:37.32806Z","shell.execute_reply":"2024-06-12T22:38:37.51707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_feature_importances(model, model_name, color_scale='Reds', dataframe=None):\n    \n    if dataframe is None:\n        raise ValueError(\"Dataframe cannot be None and must contain the feature names.\")\n\n    # Extracting feature importances and sorting them\n    importances = model.feature_importances_\n    indices = np.argsort(importances)[::-1]\n    feature_names = dataframe.columns\n\n    # Creating a DataFrame for the importances\n    feature_importances = pd.DataFrame({\n        'Feature': feature_names[indices],\n        'Importance': importances[indices]\n    })\n\n    # Plotting the feature importances\n    fig = px.bar(feature_importances.sort_values('Importance', ascending=True), \n                 x='Importance', \n                 y='Feature',\n                 title=f\"Feature Importances in {model_name}\",\n                 labels={'Importance': 'Importance', 'Feature': 'Feature'},\n                 height=1400,\n                 color='Importance',\n                 color_continuous_scale=color_scale)\n\n    fig.update_layout(xaxis_title='Importance', yaxis_title='Feature')\n\n    return fig","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:38:37.520058Z","iopub.execute_input":"2024-06-12T22:38:37.52052Z","iopub.status.idle":"2024-06-12T22:38:37.534756Z","shell.execute_reply.started":"2024-06-12T22:38:37.520476Z","shell.execute_reply":"2024-06-12T22:38:37.533503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'XGBoost'\nfig = plot_feature_importances(xgb_model, model_name, 'Bluered', X_train)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:38:37.53638Z","iopub.execute_input":"2024-06-12T22:38:37.536916Z","iopub.status.idle":"2024-06-12T22:38:39.555083Z","shell.execute_reply.started":"2024-06-12T22:38:37.536885Z","shell.execute_reply":"2024-06-12T22:38:39.553552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance_list=[]\nfeature_importances_list=[]\nfeature_importances = xgb_model.feature_importances_\nfeature_importances_list.append(feature_importances)\n\n#avg_f1 = np.mean(f1_scores)\navg_feature_importances = np.mean(feature_importances_list, axis=0)\n\nfeature_importance_listxgb = [(X_train.columns[i], importance) for i, importance in enumerate(avg_feature_importances)]\nfeature_importance_listxgb","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:38:39.556317Z","iopub.execute_input":"2024-06-12T22:38:39.556727Z","iopub.status.idle":"2024-06-12T22:38:39.57081Z","shell.execute_reply.started":"2024-06-12T22:38:39.55669Z","shell.execute_reply":"2024-06-12T22:38:39.568956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier\n\ncat_params = {\n    'verbose': 0,                       # Silent mode\n}\n\nprint('CatBoost Cross-Validation Results:\\n')\ncat_model, cat_mean_accuracy = cross_validate_model(CatBoostClassifier, X_train, y_train, cat_params)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:38:39.573061Z","iopub.execute_input":"2024-06-12T22:38:39.575144Z","iopub.status.idle":"2024-06-12T22:44:25.943102Z","shell.execute_reply.started":"2024-06-12T22:38:39.575049Z","shell.execute_reply":"2024-06-12T22:44:25.941989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the test set and reverse the label encoding\ncat_preds = cat_model.predict(X_test)\ncat_preds_labels = label_encoder.inverse_transform(cat_preds)\n\n# Save the predictions to a CSV file\ncat_result = pd.DataFrame(X_test.index)\ncat_result['Target'] = cat_preds_labels\n#cat_result.to_csv('result_cat.csv', index=False)\ncat_result","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:44:25.944518Z","iopub.execute_input":"2024-06-12T22:44:25.945236Z","iopub.status.idle":"2024-06-12T22:44:26.215872Z","shell.execute_reply.started":"2024-06-12T22:44:25.945204Z","shell.execute_reply":"2024-06-12T22:44:26.214795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature importance in CatBoost\nmodel_name = 'CatBoost'\nfig = plot_feature_importances(cat_model, model_name, 'Temps', X_train)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:44:26.217218Z","iopub.execute_input":"2024-06-12T22:44:26.217573Z","iopub.status.idle":"2024-06-12T22:44:26.297719Z","shell.execute_reply.started":"2024-06-12T22:44:26.217544Z","shell.execute_reply":"2024-06-12T22:44:26.296584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance_list=[]\nfeature_importances_list=[]\nfeature_importances = cat_model.feature_importances_\nfeature_importances_list.append(feature_importances)\n\n#avg_f1 = np.mean(f1_scores)\navg_feature_importances = np.mean(feature_importances_list, axis=0)\n\nfeature_importance_listcatbst = [(X_train.columns[i], importance) for i, importance in enumerate(avg_feature_importances)]\nfeature_importance_listcatbst","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:44:26.299098Z","iopub.execute_input":"2024-06-12T22:44:26.299412Z","iopub.status.idle":"2024-06-12T22:44:26.310825Z","shell.execute_reply.started":"2024-06-12T22:44:26.299386Z","shell.execute_reply":"2024-06-12T22:44:26.309683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nlgb_params = {\n    'verbose': -1,                    # Set to -1 for silent mode, no process information printed\n}\n\nprint('LightGBM Cross-Validation Results:\\n')\nlgb_model, lgb_mean_accuracy = cross_validate_model(LGBMClassifier, X_train, y_train, lgb_params)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:44:26.312697Z","iopub.execute_input":"2024-06-12T22:44:26.313152Z","iopub.status.idle":"2024-06-12T22:45:45.566615Z","shell.execute_reply.started":"2024-06-12T22:44:26.313112Z","shell.execute_reply":"2024-06-12T22:45:45.565351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_preds = lgb_model.predict(X_test)\nlgb_preds_labels = label_encoder.inverse_transform(lgb_preds)\n\n# Save the predictions to a CSV file\nlgb_result = pd.DataFrame(X_test.index)\nlgb_result['Target'] = lgb_preds_labels\n#lgb_result.to_csv('result_lgb.csv', index=False)\nlgb_result\n","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:45:45.567915Z","iopub.execute_input":"2024-06-12T22:45:45.5686Z","iopub.status.idle":"2024-06-12T22:45:46.716379Z","shell.execute_reply.started":"2024-06-12T22:45:45.568566Z","shell.execute_reply":"2024-06-12T22:45:46.715261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature importance in LightGBM\nmodel_name = 'LightGBM'\nfig = plot_feature_importances(lgb_model, model_name, 'Reds', X_train)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:45:46.717922Z","iopub.execute_input":"2024-06-12T22:45:46.718348Z","iopub.status.idle":"2024-06-12T22:45:46.802464Z","shell.execute_reply.started":"2024-06-12T22:45:46.718309Z","shell.execute_reply":"2024-06-12T22:45:46.801328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance_list=[]\nfeature_importances_list=[]\nfeature_importances = lgb_model.feature_importances_\nfeature_importances_list.append(feature_importances)\n\n#avg_f1 = np.mean(f1_scores)\navg_feature_importances = np.mean(feature_importances_list, axis=0)\n\nfeature_importance_listlgbm = [(X_train.columns[i], importance) for i, importance in enumerate(avg_feature_importances)]\nfeature_importance_listlgbm","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:45:46.803959Z","iopub.execute_input":"2024-06-12T22:45:46.80439Z","iopub.status.idle":"2024-06-12T22:45:46.821962Z","shell.execute_reply.started":"2024-06-12T22:45:46.804348Z","shell.execute_reply":"2024-06-12T22:45:46.820538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sort lists based on importance in descending order\nsorted_feature_importance_list_xgb = sorted(feature_importance_listxgb, key=lambda x: x[1], reverse=True)\nsorted_feature_importance_list_lgbm = sorted(feature_importance_listlgbm, key=lambda x: x[1], reverse=True)\nsorted_feature_importance_list_catbst=  sorted(feature_importance_listcatbst, key=lambda x: x[1], reverse=True)\n# Get the last 10 features from each sorted list (which will be the least important ones in descending order)\nlast_10_features_xgb = [feature[0] for feature in sorted_feature_importance_list_xgb[-10:]]\nlast_10_features_lgbm = [feature[0] for feature in sorted_feature_importance_list_lgbm[-10:]]\nlast_10_features_catbst = [feature[0] for feature in sorted_feature_importance_list_catbst[-10:]]\n# Find common features in the last 10 least important features of both lists\ncommon_last_10_features = list(set(last_10_features_xgb) & set(last_10_features_lgbm)&set(last_10_features_catbst))\n\nprint(\"Common features in the last 10 least important features for 3 models:\")\nprint(common_last_10_features)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:45:46.829627Z","iopub.execute_input":"2024-06-12T22:45:46.829993Z","iopub.status.idle":"2024-06-12T22:45:46.840062Z","shell.execute_reply.started":"2024-06-12T22:45:46.829966Z","shell.execute_reply":"2024-06-12T22:45:46.838841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train.drop(columns=[\"Target\",\"International\",\"Nacionality\",\"Marital status\",\"Curricular units 2nd sem (without evaluations)\"])\ny_train = train[\"Target\"]\n#X_train, X_val, y_train,y_val= train_test_split(X, y, test_size=0.2, random_state=42)\nX_test = test.drop(columns=[\"International\",\"Nacionality\",\"Marital status\",\"Curricular units 2nd sem (without evaluations)\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:45:46.841412Z","iopub.execute_input":"2024-06-12T22:45:46.841805Z","iopub.status.idle":"2024-06-12T22:45:46.860676Z","shell.execute_reply.started":"2024-06-12T22:45:46.841773Z","shell.execute_reply":"2024-06-12T22:45:46.859101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\n\ndef cross_validate_model(model, X_train, y_train, params, n_splits=10):\n    \"\"\"\n    Performs K-Fold cross-validation for a given model, returns the last model and average validation accuracy.\n\n    Parameters:\n        model: Machine learning model class (e.g., RandomForestClassifier)\n        X_train: Training feature dataset\n        y_train: Training target dataset\n        params: Dictionary of parameters to initialize the model\n        n_splits: Number of folds for cross-validation (default: 10)\n\n    Returns:\n        last_model: The last trained model instance\n        average_val_accuracy: Average validation accuracy over all folds\n    \"\"\"\n    # Initialize variables\n    cv = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n    val_scores = []\n\n    # Cross-validation loop\n    for fold, (train_ind, valid_ind) in enumerate(cv.split(X_train)):\n        # Data splitting\n        X_fold_train = X_train.iloc[train_ind]\n        y_fold_train = y_train.iloc[train_ind]\n        X_val = X_train.iloc[valid_ind]\n        y_val = y_train.iloc[valid_ind]\n        \n        # Model initialization and training\n        clf = model(**params)\n        clf.fit(X_fold_train, y_fold_train)\n        \n        # Predict and evaluate\n        y_pred_trn = clf.predict(X_fold_train)\n        y_pred_val = clf.predict(X_val)\n        train_acc = accuracy_score(y_fold_train, y_pred_trn)\n        val_acc = accuracy_score(y_val, y_pred_val)\n        print(f\"Fold: {fold}, Train Accuracy: {train_acc:.5f}, Val Accuracy: {val_acc:.5f}\")\n        print(\"-\" * 50)\n        \n        # Accumulate validation scores\n        val_scores.append(val_acc)\n\n    # Calculate the average validation score\n    average_val_accuracy = np.mean(val_scores)\n    print(\"Average Validation Accuracy:\", average_val_accuracy)\n\n    return clf, average_val_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:45:46.862591Z","iopub.execute_input":"2024-06-12T22:45:46.863465Z","iopub.status.idle":"2024-06-12T22:45:46.876237Z","shell.execute_reply.started":"2024-06-12T22:45:46.863419Z","shell.execute_reply":"2024-06-12T22:45:46.875018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nprint('XGBoost Cross-Validation Results:\\n')\nxgb_model, xgb_mean_accuracy = cross_validate_model(XGBClassifier, X_train, y_train, params={})","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:45:46.87783Z","iopub.execute_input":"2024-06-12T22:45:46.878565Z","iopub.status.idle":"2024-06-12T22:47:09.478357Z","shell.execute_reply.started":"2024-06-12T22:45:46.878524Z","shell.execute_reply":"2024-06-12T22:47:09.476946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the test set and reverse the label encoding\nxgb_preds = xgb_model.predict(X_test)\nxgb_preds_labels = label_encoder.inverse_transform(xgb_preds)\n\n# Save the predictions to a CSV file\nxgb_result = pd.DataFrame(X_test.index)\nxgb_result['Target'] = xgb_preds_labels\n#xgb_result.to_csv('result_xgb.csv', index=False)\nxgb_result","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:47:09.480025Z","iopub.execute_input":"2024-06-12T22:47:09.480493Z","iopub.status.idle":"2024-06-12T22:47:09.874811Z","shell.execute_reply.started":"2024-06-12T22:47:09.480447Z","shell.execute_reply":"2024-06-12T22:47:09.87369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nlgb_params = {\n    'verbose': -1,                    # Set to -1 for silent mode, no process information printed\n}\n\nprint('LightGBM Cross-Validation Results:\\n')\nlgb_model, lgb_mean_accuracy = cross_validate_model(LGBMClassifier, X_train, y_train, lgb_params)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:47:09.876427Z","iopub.execute_input":"2024-06-12T22:47:09.876884Z","iopub.status.idle":"2024-06-12T22:48:29.047431Z","shell.execute_reply.started":"2024-06-12T22:47:09.876844Z","shell.execute_reply":"2024-06-12T22:48:29.046287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_preds = lgb_model.predict(X_test)\nlgb_preds_labels = label_encoder.inverse_transform(lgb_preds)\n\n# Save the predictions to a CSV file\nlgb_result = pd.DataFrame(X_test.index)\nlgb_result['Target'] = lgb_preds_labels\n#lgb_result.to_csv('result_lgb.csv', index=False)\nlgb_result","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:48:29.049099Z","iopub.execute_input":"2024-06-12T22:48:29.04952Z","iopub.status.idle":"2024-06-12T22:48:30.157081Z","shell.execute_reply.started":"2024-06-12T22:48:29.049482Z","shell.execute_reply":"2024-06-12T22:48:30.15594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier\n\ncat_params = {\n    'verbose': 0,                       # Silent mode\n}\n\nprint('CatBoost Cross-Validation Results:\\n')\ncat_model, cat_mean_accuracy = cross_validate_model(CatBoostClassifier, X_train, y_train, cat_params)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:48:30.158472Z","iopub.execute_input":"2024-06-12T22:48:30.158841Z","iopub.status.idle":"2024-06-12T22:53:52.608787Z","shell.execute_reply.started":"2024-06-12T22:48:30.158809Z","shell.execute_reply":"2024-06-12T22:53:52.607441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the test set and reverse the label encoding\ncat_preds = cat_model.predict(X_test)\ncat_preds_labels = label_encoder.inverse_transform(cat_preds)\n\n# Save the predictions to a CSV file\ncat_result = pd.DataFrame(X_test.index)\ncat_result['Target'] = cat_preds_labels\n#cat_result.to_csv('result_cat.csv', index=False)\ncat_result","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:53:52.610868Z","iopub.execute_input":"2024-06-12T22:53:52.611311Z","iopub.status.idle":"2024-06-12T22:53:52.916168Z","shell.execute_reply.started":"2024-06-12T22:53:52.611271Z","shell.execute_reply":"2024-06-12T22:53:52.914915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Pred = pd.concat([cat_result,lgb_result,xgb_result], axis=1)['Target']\nprint(Pred)\n# Blend predictions using mode\nBlend = Pred.mode(axis=1)\n\n# Select the first mode as the blended prediction\nBlend = Blend.iloc[:, 0]\n\nprint(Blend)\n\nensemble_result = pd.DataFrame(X_test.index)\nensemble_result['Target'] = Blend\nprint(ensemble_result)\n\n# Check for null values in the DataFrame\n\n\nensemble_result.to_csv('submission.csv',index=False)\nensemble_result","metadata":{"execution":{"iopub.status.busy":"2024-06-12T22:54:26.414662Z","iopub.execute_input":"2024-06-12T22:54:26.415077Z","iopub.status.idle":"2024-06-12T22:54:44.118368Z","shell.execute_reply.started":"2024-06-12T22:54:26.415047Z","shell.execute_reply":"2024-06-12T22:54:44.116949Z"},"trusted":true},"execution_count":null,"outputs":[]}]}